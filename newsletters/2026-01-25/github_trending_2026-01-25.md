## GitHub Trending


### 1. [remotion-dev/remotion](https://github.com/remotion-dev/remotion)
> Remotion 是一个基于 React 的框架，支持使用代码和 Web 技术（如 CSS、Canvas、SVG）以编程方式创建动态视频。它允许开发者通过 React 组件、变量和 API 实现视频内容的自动化生成与复用，适用于数据可视化、个性化视频报告及动态图形制作等场景。
---

### 2. [OpenBMB/UltraRAG](https://github.com/OpenBMB/UltraRAG)
> UltraRAG v3 是一个基于模型上下文协议（MCP）的低代码框架，用于快速构建和编排复杂的检索增强生成（RAG）工作流。它将检索、生成等核心组件模块化为独立服务，开发者仅需通过YAML配置即可实现条件分支、循环等复杂逻辑的可视化编排，显著降低了RAG系统的开发门槛与调试难度，适用于研究探索和工业原型开发。
---

### 3. [ai-dynamo/dynamo](https://github.com/ai-dynamo/dynamo)
> NVIDIA Dynamo 是一个数据中心级分布式推理服务框架，专为多节点环境部署生成式AI与推理模型设计。它通过解耦预填充与解码、动态GPU调度、LLM感知请求路由等核心技术，实现高吞吐、低延迟的大模型推理，并兼容主流推理引擎。
---

### 4. [browser-use/browser-use](https://github.com/browser-use/browser-use)
> Browser-Use是一个开源AI浏览器自动化框架，旨在让网站对AI智能体可访问。它通过Python库和云服务，使开发者能轻松构建执行网页任务的智能体，如填写表单、购物比价。其核心优势是低延迟、支持自定义工具，并提供优化模型以提升任务完成效率。
---

### 5. [microsoft/Data-Science-For-Beginners](https://github.com/microsoft/Data-Science-For-Beginners)
> 微软推出的10周20课数据科学入门课程，采用项目式教学，包含课前课后测验、详细指导和作业。课程结构清晰，支持多语言，适合零基础学习者通过实践快速掌握核心技能。
---

### 6. [microsoft/VibeVoice](https://github.com/microsoft/VibeVoice)
> 微软开源的VibeVoice是一系列前沿语音AI模型，包含长语音识别与合成功能。其核心创新在于采用7.5Hz超低帧率连续语音分词器，结合大语言模型与扩散模型，能一次性处理长达60分钟的音频并生成带说话人、时间戳的结构化文本，或合成长达90分钟的多说话人对话语音。适用于长会议记录、播客生成等场景，在长上下文处理上具有显著优势。
---

### 7. [github/copilot-cli](https://github.com/github/copilot-cli)
> GitHub Copilot CLI 将 AI 编程助手引入终端，支持通过自然语言对话进行代码构建、调试和理解。它深度集成 GitHub 工作流，具备代理能力以规划和执行复杂任务，并允许用户在操作前预览确认。适用于需要在命令行环境中获得智能编码协助的开发者。
---

### 8. [anthropics/claude-code](https://github.com/anthropics/claude-code)
> Claude Code是一款基于终端的AI编程助手，能理解代码库上下文，通过自然语言指令执行常规任务、解释复杂代码、处理Git工作流，显著提升开发效率。
---

### 9. [lyogavin/airllm](https://github.com/lyogavin/airllm)
> AirLLM通过优化推理内存使用，无需量化、蒸馏或剪枝，即可在单张4GB GPU上运行700亿参数大模型，并支持在8GB显存上运行4050亿参数的Llama3.1。其采用分层加载与块级量化压缩技术，显著提升推理速度，适用于资源受限环境下的高效大模型部署。
---

### 10. [block/goose](https://github.com/block/goose)
> Goose是一款本地化、可扩展的开源AI智能体，能自动化执行复杂开发任务。它超越代码建议，可自主构建项目、编写执行代码、调试并编排工作流。支持任意LLM与多模型配置，集成MCP服务器，提供桌面应用和CLI，是提升开发效率的创新助手。
---

### 11. [deepseek-ai/FlashMLA](https://github.com/deepseek-ai/FlashMLA)
> FlashMLA是DeepSeek优化的注意力计算核心库，为DeepSeek-V3系列模型提供高性能支持。它实现了稀疏与稠密注意力内核，在预填充和解码阶段显著提升效率，支持FP8 KV缓存，在H800 GPU上解码性能可达660 TFLOPS。适用于需要高效大模型推理的场景。
---

### 12. [KellerJordan/modded-nanogpt](https://github.com/KellerJordan/modded-nanogpt)
> 该项目通过集成旋转嵌入、Muon优化器、Flash Attention 3等多项前沿技术，将NanoGPT模型在8块H100 GPU上的训练时间从45分钟大幅缩短至100秒以内。它专注于高效语言模型训练，适用于需要快速迭代实验的研究者和工程师，展示了通过算法与系统优化极致提升训练效率的潜力。
---

### 13. [Asabeneh/30-Days-Of-Python](https://github.com/Asabeneh/30-Days-Of-Python)
> 这是一个为期30天的Python编程学习项目，提供从基础语法到Web开发、数据分析和API构建的完整教程。它采用渐进式学习路径，包含大量实践练习，适合编程新手系统掌握Python核心技能并应用于实际开发场景。
---
