- **[DeepSeek发布R1T2系列模型](https://twitter.com/reach_vb/status/1940536684061643239)**（来源：Twitter）  
> DeepSeek推出R1T2模型，速度提升200%，在GPQA和AIME 24等基准测试表现优异，采用专家组装方法训练，MIT许可开源。

- **[Together AI开源DeepSWE编码代理](https://twitter.com/tri_dao/status/1940765882227347585)**（来源：Twitter）  
> Together AI基于Qwen3-32B开发的开源软件工程代理DeepSWE，在SWE-Bench-Verified测试中达到59%准确率，完整训练工具包已开源。

- **[NVIDIA GB300 NVL72开始部署](https://twitter.com/weights_biases/status/1940818055271272917)**（来源：Twitter）  
> CoreWeave成为首家部署NVIDIA GB300 NVL72系统的云服务商，该平台采用新型架构，专为大规模AI训练和推理优化。

- **[ZLUDA项目实现非NVIDIA GPU的CUDA兼容](https://github.com/vosen/ZLUDA)**（来源：GitHub）  
> ZLUDA可在AMD Radeon RX 5000+ GPU上运行未经修改的CUDA应用，性能接近原生，采用Rust开发，支持Windows/Linux系统。

- **[MIT研究揭示ChatGPT对不同学习者的影响差异](https://arxiv.org/pdf/2506.08872)**（来源：arXiv）  
> 研究表明高能力者用LLM整合知识，低能力者倾向直接获取答案，影响深度学习效果。

- **[vosen/ZLUDA](https://github.com/vosen/ZLUDA)**（来源：GitHub）  
> 非NVIDIA显卡的CUDA兼容层，性能接近原生，支持Windows和Linux系统，为AMD显卡用户提供运行CUDA应用新选择。

- **[Launch HN: Morph (YC S23) – 以每秒4500令牌的速度应用AI代码编辑](https://news.ycombinator.com/item?id=44490863)**（来源：Hacker News）  
> Morph推出高速AI代码编辑模型，支持4500+ tokens/秒的直接文件修改，避免全文件重写或搜索替换。

- **[罗马仕宣布停工停产6个月](https://36kr.com/p/3367635580241920?f=rss)**（来源：36Kr）  
> 充电宝行业因电芯缺陷和内卷竞争陷入危机，安克创新等厂商同步受波及。

- **[DeepSeek降本秘诀曝光：2招极致压榨推理部署](https://36kr.com/p/3365449318172675?f=rss)**（来源：36Kr）  
> DeepSeek R1大幅降低推理模型价格，第三方平台使用量增长20倍，但服务质量妥协导致延迟高。

- **[AIGC独角兽硅基智能完成D轮融资](https://36kr.com/p/3362675516901129?f=rss)**（来源：36Kr）  
> 硅基智能完成数亿元D轮融资，聚焦数字人技术研发与商业化应用，已服务5000余家品牌。