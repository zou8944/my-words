- **[Kimi Linear (KDA)发布，实现长上下文高效处理](https://twitter.com/Kimi_Moonshot/status/1983937694360322136)**（来源：Moonshot AI）  
  > 开源混合注意力架构，KV缓存减少75%，解码吞吐量提升6倍，长上下文推理质量优于全注意力机制

- **[Hugging Face发布200+页Smol训练手册](https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook)**（来源：Hugging Face）  
  > 涵盖预训练数据管理、架构选择到后训练优化，强调消融实验和论文中常被忽略的实战问题

- **[nano-vllm：轻量级大语言模型推理引擎](https://github.com/GeeeekExplorer/nano-vllm)**（来源：GitHub）  
  > 1200行Python实现核心优化，RTX 4070实测吞吐量达1434 token/秒，性能超越原版vLLM

- **[DeepCode：多智能体代码生成框架](https://github.com/HKUDS/DeepCode)**（来源：GitHub）  
  > 支持论文算法复现和前后端开发，在OpenAI PaperBench基准测试中超越人类专家

- **[反对PGVector的理由](https://news.ycombinator.com/item?id=45798479)**（来源：Hacker News）  
  > 分析PGVector在生产环境的前置过滤缺陷和查询规划复杂性，对比专业向量数据库优劣

- **[微软Agent Lightning智能体训练框架](https://github.com/microsoft/agent-lightning)**（来源：GitHub）  
  > 零代码优化现有智能体，集成强化学习和自动提示优化，支持多智能体系统选择性优化

- **[Meta REFRAG项目优化长上下文处理](https://news.ycombinator.com/item?id=45800249)**（来源：Hacker News）  
  > 预计算向量直输LLM，首令牌生成快31倍，迭代令牌快3倍，整体吞吐量提升7倍

- **[学会阅读Arthur Whitney的C代码](https://news.ycombinator.com/item?id=45800777)**（来源：Hacker News）  
  > 解析极简C代码设计哲学，提升底层编程智慧和系统优化能力

- **[Voyage-3-large嵌入模型登顶HF RTEB榜](https://twitter.com/_avichawla/status/1983783708047093838)**（来源：Voyage AI）  
  > 量化感知训练在33个数据集排名第一，金融/法律/医疗检索任务超越OpenAI/Cohere

- **[Lightning-SimulWhisper：苹果芯片实时语音识别](https://news.ycombinator.com/item?id=45620534)**（来源：Hacker News）  
  > CoreML/MLX移植版比PyTorch快15倍，平衡内存与准确率，实现设备端低延迟语音转录