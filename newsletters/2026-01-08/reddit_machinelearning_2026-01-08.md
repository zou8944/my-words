## Reddit ML - 2026-01-08


### 1. [[R] DeepSeek-R1论文两天前更新，从22页扩充至86页，并补充了大量细节。](https://www.reddit.com/r/MachineLearning/comments/1q6cb0k/r_deepseekr1s_paper_was_updated_2_days_ago/)
> DeepSeek-R1论文大幅更新，从22页扩充至86页，增加了大量细节内容。

<sub>作者: /u/Nunki08 | 发布于: 2026-01-07 10:50</sub>

---

### 2. [ICLR新审稿人体验如何？](https://www.reddit.com/r/MachineLearning/comments/1q67hiq/d_iclr_new_acs_hows_it_going/)
> 用户询问ICLR新审稿系统的使用体验，包括任务量、无可靠分数下的审稿帮助以及决策流程。

<sub>作者: /u/plantparent2021 | 发布于: 2026-01-07 05:58</sub>

---

### 3. [[项目] 从零重构模糊模式Tsetlin机：训练速度提升10倍，推理速度提升34倍（每秒3200万次预测），并支持文本生成](https://www.reddit.com/r/MachineLearning/comments/1q6igw3/p_reengineered_the_fuzzypattern_tsetlin_machine/)
> 作者重构了模糊模式Tsetlin机，通过缓存优化和SIMD指令，使训练速度提升10倍，推理速度提升34倍，并展示了其在生成式任务中的应用。

<sub>作者: /u/ArtemHnilov | 发布于: 2026-01-07 15:33</sub>

---

### 4. [[讨论] RTX 5090 / 50系列CuPy配置指南（需Blackwell架构与CUDA 13.1）](https://www.reddit.com/r/MachineLearning/comments/1q61evy/d_rtx_5090_50series_cupy_setup_blackwell/)
> RTX 50系列显卡需CUDA 13.1，CuPy需从源码安装，并提供了具体步骤和故障排除指南。

<sub>作者: /u/Busy-as-usual | 发布于: 2026-01-07 01:16</sub>

---

### 5. [[D] 实验室内部合作](https://www.reddit.com/r/MachineLearning/comments/1q6sgx5/d_intralab_collaborations/)
> 一位有AI背景的医生在学术医院工作，常被同事咨询项目核心问题。他困惑于如何区分一般帮助与合作研究，并询问如何恰当地提出合作作者身份。

<sub>作者: /u/valuat | 发布于: 2026-01-07 21:37</sub>

---

### 6. [[R] tinyaleph：利用质数与超复数代数实现语义编码的库](https://www.reddit.com/r/MachineLearning/comments/1q6t07j/r_tinyaleph_a_library_for_encoding_semantics/)
> tinyaleph是一个实验性语义计算库，使用质数编码概念并嵌入16维超复数空间，通过振荡器同步实现推理。

<sub>作者: /u/sschepis | 发布于: 2026-01-07 21:57</sub>

---

### 7. [[D] 如何在arXiv上获得预印本发布的认可？](https://www.reddit.com/r/MachineLearning/comments/1q68ues/d_how_do_i_find_endorsement_to_publish_preprint/)
> 作者寻求在arXiv发布论文的指导，需要获得新用户所需的背书，并愿意分享论文以获取帮助。

<sub>作者: /u/StationFrosty | 发布于: 2026-01-07 07:15</sub>

---

### 8. [[R] 共振注意力：一种基于素数索引的超复数注意力机制](https://www.reddit.com/r/MachineLearning/comments/1q6uwky/r_resonant_attention_a_primeindexed_hypercomplex/)
> 提出一种新型注意力机制，用稀疏质数索引向量和四元数方向替代传统点积，实现O(n log n)复杂度，并保持语义顺序敏感性。

<sub>作者: /u/sschepis | 发布于: 2026-01-07 23:10</sub>

---
