## Reddit ML - 2026-01-16


### 1. [英伟达：长上下文端到端测试时训练技术，实现模型权重实时更新 | "TTT将范式从检索信息转变为实时学习...模型将上下文窗口视为数据集并实时自我训练。"](https://www.reddit.com/r/MachineLearning/comments/1qd696s/nvidia_endtoend_testtime_training_for_long/)
> 英伟达提出测试时训练方法，让模型在推理时实时学习上下文信息，实现长文本处理的高效与准确。

<sub>作者: /u/44th--Hokage | 发布于: 2026-01-15 01:43</sub>

---

### 2. [[项目] Go语言中针对LLM流量的自适应负载均衡——比预想中更难](https://www.reddit.com/r/MachineLearning/comments/1qdsd84/p_adaptive_load_balancing_in_go_for_llm_traffic/)
> 开源贡献者分享Go语言实现LLM流量自适应负载均衡的经验，通过实时指标动态调整权重，利用原子操作避免锁竞争，优化连接池提升性能。

<sub>作者: /u/dinkinflika0 | 发布于: 2026-01-15 18:58</sub>

---

### 3. [ISBI 2026：结果公布 [D]](https://www.reddit.com/r/MachineLearning/comments/1qdcqp3/isbi_2026_results_out_d/)
> ISBI 2026会议结果已公布，延期一个月，本次录取率较高，作者询问医学成像领域同行的投稿情况。

<sub>作者: /u/ade17_in | 发布于: 2026-01-15 07:02</sub>

---

### 4. [[R] 机器学习与认知科学中的统计学习对比](https://www.reddit.com/r/MachineLearning/comments/1qdmdva/r_statistical_learning_in_machine_learning_vs/)
> 研究者寻求认知科学与机器学习中统计学习的异同，包括定义、概念差异、预测和测试方法，以撰写综述。

<sub>作者: /u/Ok_Fudge1993 | 发布于: 2026-01-15 15:22</sub>

---

### 5. [[论文] arXiv新评：高性能无服务器是AI推理的未来（静态集群正走向消亡）](https://www.reddit.com/r/MachineLearning/comments/1qdmbk2/d_new_arxiv_review_highperformance_serverless_is/)
> 一篇arXiv综述指出，静态GPU集群难以高效处理突发性AI负载，业界正转向弹性无服务器架构以解决资源浪费和性能瓶颈问题。

<sub>作者: /u/pmv143 | 发布于: 2026-01-15 15:20</sub>

---
