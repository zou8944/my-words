## Reddit ML - 2026-01-22


### 1. [[D] 你是否觉得公司在招聘研究员时，会套取或滥用研究者的创意？](https://www.reddit.com/r/MachineLearning/comments/1qj3t98/d_do_you_feel_like_companies_are_scooping_abusing/)
> 求职者怀疑公司借面试任务获取免费劳动，故意未展示全部研究仍遭质疑，质疑面试流程的公平性。

<sub>作者: /u/quasiproductive | 发布于: 2026-01-21 17:13</sub>

---

### 2. [[D] CVPR 2026 论文评审](https://www.reddit.com/r/MachineLearning/comments/1qis2rj/d_cvpr_2026_paper_reviews/)
> CVPR 2026论文评审结果即将在24小时内公布，此帖旨在为相关讨论提供一个交流平台。

<sub>作者: /u/akshitsharma1 | 发布于: 2026-01-21 08:03</sub>

---

### 3. [[D] Wandb让我焦虑不已…](https://www.reddit.com/r/MachineLearning/comments/1qj1hkk/d_wandb_gives_me_anxiety/)
> 用户表示自己沉迷于频繁查看训练进度，使用wandb工具已近乎成瘾。

<sub>作者: /u/casualcreak | 发布于: 2026-01-21 15:50</sub>

---

### 4. [[D] 你们在K8s上如何处理GPU资源浪费问题？](https://www.reddit.com/r/MachineLearning/comments/1qj0bcc/d_how_do_you_guys_handle_gpu_waste_on_k8s/)
> 用户管理PyTorch训练集群时，GPU利用率仅30-40%，成本高昂。怀疑因任务请求过多GPU后，数据加载成为瓶颈导致资源闲置。求助更有效的监控或解决方法。

<sub>作者: /u/k1m0r | 发布于: 2026-01-21 15:06</sub>

---

### 5. [[讨论] ICML合格审稿人](https://www.reddit.com/r/MachineLearning/comments/1qj94co/d_icml_qualified_reviewers/)
> 作者询问ICML投稿中“合格审稿人”的定义，疑惑若作者无顶级会议发表，其他会议是否算数。

<sub>作者: /u/Massive_Horror9038 | 发布于: 2026-01-21 20:23</sub>

---

### 6. [产品目录中的商品聚类](https://www.reddit.com/r/MachineLearning/comments/1qjb6va/clustering_products_in_catalogue_r/)
> 用户寻求对100万种多模态嵌入产品进行聚类的方法，以识别不同商家的变体或重复产品。

<sub>作者: /u/ogvisit2 | 发布于: 2026-01-21 21:40</sub>

---

### 7. [贝叶斯物理信息神经网络（PINNs）[R]](https://www.reddit.com/r/MachineLearning/comments/1qj610w/bayesian_physics_informed_neural_networks_pinns_r/)
> 用户询问贝叶斯物理信息神经网络中不确定性的建模方式，特别是哪些组件被概率化处理。

<sub>作者: /u/LifeProgrammer7169 | 发布于: 2026-01-21 18:32</sub>

---

### 8. [[论文笔记] 语言模型物理原理研究综述](https://www.reddit.com/r/MachineLearning/comments/1qipx4e/p_notes_from_physics_of_language_models_papers/)
> 分享两篇关于语言模型物理原理论文的笔记，分别探讨隐藏推理过程与知识存储提取机制。

<sub>作者: /u/shreyansh26 | 发布于: 2026-01-21 05:59</sub>

---

### 9. [[讨论] 多重共线性下SHAP评估的可靠性分析](https://www.reddit.com/r/MachineLearning/comments/1qj2qlr/d_evaluating_shap_reliability_in_the_presence_of/)
> SHAP等可解释AI方法在处理高度相关的特征时，其解释结果会受到多重共线性的影响，可靠性存疑。作者就此寻求应对方案。

<sub>作者: /u/Nicholas_Geo | 发布于: 2026-01-21 16:35</sub>

---

### 10. [[讨论] Vision Transformer (ViT) 如何处理可变尺寸图像？](https://www.reddit.com/r/MachineLearning/comments/1qizsbz/d_vision_transformer_vit_how_do_i_deal_with/)
> 用户询问在构建ViT模型时如何处理不同尺寸的图像进行训练，并考虑使用缩放和填充黑色像素的方法是否可行。

<sub>作者: /u/PositiveInformal9512 | 发布于: 2026-01-21 14:46</sub>

---

### 11. [[讨论] 不小心超过了IJCAI投稿页数限制](https://www.reddit.com/r/MachineLearning/comments/1qj2e8z/d_accidentally_went_over_ijcai_submission_page/)
> 作者首次投稿IJCAI会议，误将总页数9页理解为全部内容，实际应为正文7页加参考文献2页。现已超截止日期，担心被直接拒稿并求助。

<sub>作者: /u/d_edge_sword | 发布于: 2026-01-21 16:22</sub>

---

### 12. [本周AI/ML动态：地缘政治博弈、推理模型突破、长上下文进展与安全转向](https://www.reddit.com/r/MachineLearning/comments/1qip6ld/d_this_week_in_aiml_geopolitics_reasoning_models/)
> 过去一周AI领域进展显著：中美欧政策聚焦安全与监管，谷歌、DeepSeek推出新推理模型，MIT研究突破长上下文处理，行业投资转向人机协同。

<sub>作者: /u/tomsweetas | 发布于: 2026-01-21 05:20</sub>

---
