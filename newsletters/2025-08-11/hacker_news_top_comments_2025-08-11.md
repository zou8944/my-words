## Hacker News 高赞评论 - 2025-08-11


### 1. [Uehreka在"GPT-5：姗姗来迟、过度炒作且令人失望，这还不是最糟的"一文中发表新评论](https://news.ycombinator.com/item?id=44851706)
> 这类文章特别让我反感。作者没有基于自己的分析来阐述为什么他认为GPT-5不好，而是收集了一堆社交媒体反应，把每条批评都夸张地描述成"毁灭性打击"或"猛烈抨击"，然后指望这些过度渲染的总结能说服读者认同他的观点。
> 
> 这种写法既不够客观称不上新闻报道，又缺乏原创性算不上分析评论。

<sub>作者: Uehreka | 发布于: 2025-08-10 00:32</sub>

---

### 2. [ryandrake在"Show HN: 根据您的大致位置显示当前天空的CSS渐变效果"中的新评论](https://news.ycombinator.com/item?id=44846565)
> 太棒了。记得在我职业生涯早期，曾参与开发一款3D逐向导航软件，当时有个任务是绘制背景天空。团队里的资深同事说，白天画个蓝色矩形，晚上画个深灰色矩形就完事了。但我偏要迎难而上，查阅了基于环境、经纬度、时间等因素的天空渲染文献——当时参考的是Preetham的《日光实用分析模型》[1]，为软件构建了完全拟真的天空模型。我甚至还用硬编码的星历表添加了主要恒星。运行效率也很不错。
> 
> 结果领导们当然不买账，他们无法理解为什么地平线会有雾蒙蒙的泛黄效果。"竞争对手的天空都是纯蓝色的！" 我用"你睁眼看看真实天空"来回应显然不受待见。
> 
> 最终我被要求砍掉这个功能，改回画蓝色矩形 :(
> 
> 说这么多就是想表达：这个网站做得真棒！
> 
> 1: [https://courses.cs.duke.edu/cps124/fall01/resources/p91-pree...](https://courses.cs.duke.edu/cps124/fall01/resources/p91-preetham.pdf)

<sub>作者: ryandrake | 发布于: 2025-08-09 14:07</sub>

---

### 3. [canyon289在"Ask HN: ChatGPT如何服务7亿用户而我本地连一个GPT-4都跑不起来？"中的新评论](https://news.ycombinator.com/item?id=44840935)
> 我每天都在谷歌从事这些系统的工作（免责声明：以下仅代表个人观点，不代表公司立场）。所以一方面我可以告诉你，确实有聪明人在深入思考这个问题的每个方面，但另一方面我也不能透露太多细节。
> 
> 不过我可以分享同事写的这份资料！里面详细解释了加速器架构设计以及实现高性能的各种考量因素：
> <https://jax-ml.github.io/scaling-book/>
> 
> 你特别关心的推理问题，正是这一章的重点内容：
> <https://jax-ml.github.io/scaling-book/inference/>
> 
> 补充：另一个很棒的资源是unsloth指南。他们团队特别擅长深入分析各种模型并找出优化方案，而且文档写得非常出色。这是Gemma 3n的指南，你还能找到其他模型的优化方法：
> [https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune...](https://docs.unsloth.ai/basics/gemma-3n-how-to-run-and-fine-tune)

<sub>作者: canyon289 | 发布于: 2025-08-08 19:47</sub>

---

### 4. [牛肉在"GPT-5"话题下的新评论](https://news.ycombinator.com/item?id=44828331)
> 或许通过随机模型预测文本来模拟更高层次的智能是不可能的。
> 
> 我并非AI研究员，但有些朋友从事这个领域。他们并不担心基于大语言模型(LLM)的通用人工智能(AGI)，因为随着训练数据量的增加，效果提升的边际效益正在递减。这可能就是瓶颈所在。
> 
> 人类智能与LLM有着显著差异：人类学习所需的样本量少得多，泛化能力也强得多。而LLM往往只会复述训练数据中已有解决方案的问题，这些方案通常在训练数据中被充分记录。
> 
> 话虽如此，要实现彻底改变世界的AI，AGI并非必要条件。现有的AI/机器学习(ML)/监督学习(SL)技术中，可能存在着比通用智能更具影响力的应用场景。搜索引擎就是一个例子——能够从多领域复述知识的能力在这里反而是优势。

<sub>作者: beeflet | 发布于: 2025-08-07 18:17</sub>

---

### 5. [高频用户在"GPT-5"话题下发表新评论](https://news.ycombinator.com/item?id=44828137)
> 经常有人提出，一旦某家AI公司突破通用人工智能(AGI)的门槛，就会甩开其他竞争者。但有趣的是，至少到目前为止趋势恰恰相反：随着时间的推移和模型性能的提升，各家公司的表现反而越来越接近。目前GPT-5、Claude Opus、Grok 4和Gemini 2.5 Pro在各方面表现都很出色（比如它们基本都能解决中等难度的数学和编程问题）。
> 
> 作为用户，感觉这场竞赛从未像现在这样势均力敌。虽然外推可能不太严谨，但这让我对"硬起飞/赢家通吃"的主流观点产生了更多怀疑。
> 
> 很想知道这些公司的研究人员怎么看——你们预计未来几年竞争对手的AI产品会继续保持这种激烈竞争、差距缩小的态势，还是会出现分化？

<sub>作者: highfrequency | 发布于: 2025-08-07 18:05</sub>

---

### 6. [surround在"GPT-5"话题下的新评论](https://news.ycombinator.com/item?id=44827929)
> GPT-5的知识截止日期：2024年9月30日（发布前10个月）
> 
> 对比来看：
> 
> Gemini 2.5 Pro的知识截止日期：2025年1月（发布前3个月）
> 
> Claude Opus 4.1的知识截止日期：2025年3月（发布前4个月）
> 
> <https://platform.openai.com/docs/models/compare>
> 
> <https://deepmind.google/models/gemini/pro/>
> 
> [https://docs.anthropic.com/en/docs/about-claude/models/overv...](https://docs.anthropic.com/en/docs/about-claude/models/overview)

<sub>作者: surround | 发布于: 2025-08-07 17:53</sub>

---

### 7. [peterdsharpe在"GPT-5"话题下的新评论](https://news.ycombinator.com/item?id=44827735)
> 这完全错了。如果这种解释成立，平板翼型就不可能产生升力了（但实际上是可以的）。
> 
> 来源：航空设计博士

<sub>作者: peterdsharpe | 发布于: 2025-08-07 17:43</sub>

---

### 8. [pram在"GPT-5"话题下的新评论](https://news.ycombinator.com/item?id=44827352)
> 我们现在正处于LLM（大语言模型）的"发烧友阶段"，人们开始讨论模型在声场表现、音质调校和齿音抑制等方面的改进

<sub>作者: pram | 发布于: 2025-08-07 17:19</sub>

---

### 9. [mtlynch在"GPT-5"话题下的新评论](https://news.ycombinator.com/item?id=44827179)
> 他们那个SWE基准测试图表是怎么回事？[0]
> 
> GPT-5非思考模式标着52.8%准确率，但o3显示的柱状图短得多，却标注着69.1%。而4o的柱子和o3完全一样长，却标着30.8%...
> 
> [0] <https://i.postimg.cc/DzkZZLry/y-axis.png>

<sub>作者: mtlynch | 发布于: 2025-08-07 17:10</sub>

---

### 10. [t_mann在"发送一次性验证码比密码更不安全"中的新评论](https://news.ycombinator.com/item?id=44821089)
> 通行密钥(Passkeys)的问题比单纯丢失设备导致无法访问(实际上通过合理设置可以避免)要复杂得多。最严重的问题在于认证机制(attestations)，这让服务提供商可以封禁那些使用赋予用户更多自由工具的用户。通行密钥，或者更广义地说挑战-响应协议(challenge-response protocols)，本可以成为密码的绝佳替代方案，实现双赢。但遗憾的是，从实际设计来看，它们主要将用于进一步巩固科技巨头的垄断地位，剥夺用户自由。

<sub>作者: t_mann | 发布于: 2025-08-07 05:58</sub>

---

### 11. [DecoPerson在"发送一次性验证码比密码更不安全"中的新评论](https://news.ycombinator.com/item?id=44820331)
> 这种攻击模式是：
> 
> 1) 用户访问恶意网站并注册账号
> 
> 2) 恶意网站提示："我们已发送验证邮件，请输入6位验证码！邮件将由GOOD平台发出，因为他们是我们的登录合作伙伴。"
> 
> 3) 恶意网站的机器人使用用户邮箱在GOOD平台发起"邮件一次性验证码登录"流程
> 
> 4) GOOD平台向用户邮箱发送一次性登录验证码
> 
> 5) 用户极易信任这封邮件，因为确实来自GOOD平台 - 如果不是合法登录，GOOD怎么会发验证码呢？
> 
> 6) 用户在恶意网站输入收到的验证码
> 
> 7) 攻击者利用该验证码以用户身份登录GOOD平台，完全控制用户账户
> 
> 这就是为什么"邮件发送一次性验证码"是最容易被钓鱼的认证方式之一。用户实在太容易犯这个错误了。
> 
> "点击邮件中的链接"稍好一些，因为会直接跳转至GOOD官网，而把这个链接转发给恶意网站更麻烦也更可疑。但如果某些主流邮件服务突然屏蔽你的登录邮件或其中的登录链接，大量用户就会立即无法登录。
> 
> 通行密钥(Passkeys)才是正解。密码管理器对通行密钥的支持已经相当完善。我可以肯定地说，即使用户丢失手机导致所有通行密钥失效，也比当前密码系统面临的问题好千万倍。我宁愿让老奶奶去银行重新验证身份，也不愿看到她的账户被钓鱼者盗走全部积蓄。

<sub>作者: DecoPerson | 发布于: 2025-08-07 03:37</sub>

---

### 12. [duskwuff在"9位字节会更好"讨论中的新评论](https://news.ycombinator.com/item?id=44818052)
> 从硬件角度来看，非2的幂次方尺寸会带来诸多不便。许多优化乘法器的设计都依赖于操作数能被对半分割的特性，这在9位单元上就无法实现。此外，用固定位数表示比特位置也很实用（例如3位表示0-7，5位表示0-31，6位表示0-63），比如用于描述位移操作次数或从字节中选择某一位；但9位情况下这种机制就会失效——你必须使用4位来表示，其中还会产生大量无效值。

<sub>作者: duskwuff | 发布于: 2025-08-06 21:27</sub>

---

### 13. [hyperpape在《我们本不该需要锁文件》中的新评论](https://news.ycombinator.com/item?id=44813767)
> 但如果你想要一个现存的例子：看看Maven。Java库生态系统已经蓬勃发展了20年，在这期间我们从未需要过锁文件。而且我们经常为了输出两行文本就引入数百个库，这说明它确实被大规模使用着。
> 
> 默认情况下，Maven不会检查传递依赖的版本冲突。要实现这个功能，你需要使用一个令人抓狂的插件，它产生的错误信息比NPM还要糟糕得多：[链接]。
> 
> 当两个库引入不同版本时，Maven如何解决依赖关系？它的处理方式简直匪夷所思。[链接]
> 
> 千万别天真地以为Maven的依赖解析不是场噩梦（不过我确实喜欢它按创建者命名空间划分包的方式，npm真该借鉴这点）。

<sub>作者: hyperpape | 发布于: 2025-08-06 15:59</sub>

---

### 14. [pentamassiv在《我给AI装上四肢后它拒绝了我》中的新评论](https://news.ycombinator.com/item?id=44808997)
> 大家好，我是这篇博客文章的作者。感谢你分享这篇文章。如果有什么问题欢迎随时提问，也请告诉我文章写得如何。这是我最初写的几篇文章之一，所以很希望能得到改进建议。

<sub>作者: pentamassiv | 发布于: 2025-08-06 07:50</sub>

---

### 15. [pentamassiv在"Ask HN: 你是否后悔开源过某个项目？"中的新评论](https://news.ycombinator.com/item?id=44805556)
> 我是一个模拟键盘鼠标输入的库的维护者。这个项目不是我创建的，但我接手了维护工作并几乎重写了所有代码。最近发现Anthropic公司正在Claude桌面版中集成这个库，可能是用于某个尚未发布的"计算机使用"类功能。我注意到他们正好在负责这个实现的团队有个空缺职位，就申请了。几个月后收到了拒绝信，理由是团队没时间面试更多候选人了。代码采用MIT许可证，所以一切都没问题。像Anthropic这样的公司使用我的代码是件好事，但如果能从中获得些回报就更好了。关于这个话题我写了篇更详细的博客：
> 
> <https://grell.dev/blog/ai_rejection>

<sub>作者: pentamassiv | 发布于: 2025-08-05 22:59</sub>

---

### 16. [erulabs在"Ask HN: 你是否曾后悔开源某个项目？"中的新评论](https://news.ycombinator.com/item?id=44805363)
> 我14岁左右时开源了一个自动配置X11的xrandr脚本。代码写得很烂，有不少bug。我在KDE邮件列表里提到这个项目，结果一位KDE核心贡献者说这代码太丢人了，叫我去死。这事对我打击很大，之后我再也没给KDE或X11贡献过代码，大概花了一年时间才重新燃起编程的热情。
> 
> 相比之下，我后来开源的其他项目都顺利多了。

<sub>作者: erulabs | 发布于: 2025-08-05 22:37</sub>

---

### 17. [cco在"OpenAI的开源模型"中的新评论](https://news.ycombinator.com/item?id=44804397)
> 我觉得大家都没抓住重点。
> 
> gpt-oss:20b可是全球前十的模型（在MMLU基准测试中仅次于Gemini-2.5-Pro），而我刚刚就在去年买的M3芯片Macbook Air上本地运行了它。
> 
> 我一直在笔记本和手机（Pixel 9 Pro）上测试各种本地模型，原本以为还要一两年才能达到这种水平。
> 
> 但现实是，今天我们就做到了。一个近乎顶尖的模型，仅需耗电成本（基本可以忽略不计）就能在我的笔记本上运行。不需要每月200美元的订阅费，也不会消耗海量资源。
> 
> 这真的太让人震撼了。

<sub>作者: cco | 发布于: 2025-08-05 21:13</sub>

---

### 18. [kridsdale3在"Claude Opus 4.1"中的新评论](https://news.ycombinator.com/item?id=44802150)
> 根据公历和地球轨道运行规律，八月才刚刚开始。

<sub>作者: kridsdale3 | 发布于: 2025-08-05 18:26</sub>

---

### 19. [foundry27在"OpenAI的开源模型"话题下的新评论](https://news.ycombinator.com/item?id=44801714)
> 模型卡片（给对技术细节感兴趣的人）：[链接]
> 
> 我正将他们描述的模型架构与主流开源权重模型（Deepseek、Qwen、GLM、Kimi）进行对比。老实说，从技术层面看只能说"还行"：
> 
> - 两个模型都采用标准分组查询注意力（64个查询头，8个KV头）。卡片提到他们沿用了GPT3的老优化方案：在带状窗口（稀疏，128 token）和全密集注意力模式间交替。使用YaRN扩展的RoPE（实现131K上下文窗口）。所以他们没有采用Deepseek的"秘制"多头潜在注意力，也没有其他GQA改进方案。
> 
> - 都是标准MoE架构。120B参数模型（总参116.8B，激活5.1B）使用128个专家和Top-4路由。采用某种带门控的SwiGLU激活函数，卡片称其"非传统"是因为钳位操作和某些残差连接。同样没有采用Deepseek的"共享专家"（通用模式）+ "路由专家"（专项任务）架构改进，或Qwen的负载均衡策略等。
> 
> - 我认为最有趣的是他们的量化方案。通过某种方法将90%以上参数量化为MXFP4格式（4.25比特/参数），让120B模型能塞进单个80GB GPU，这很酷。不过我们还有Unsloth著名的1.58比特量化方案 :)
> 
> 总之，虽然他们在智能体行为和推理训练方面确实出色，但似乎把真正的技术进步都"藏着掖着"。

<sub>作者: foundry27 | 发布于: 2025-08-05 17:57</sub>

---

### 20. [pitpatagain在"Ozempic试验显示抗衰老效果"中的新评论](https://news.ycombinator.com/item?id=44801396)
> 这项研究专门针对HIV相关脂肪代谢异常患者，这类症状与加速衰老相关。尚不清楚该研究结果对普通人群的意义。

<sub>作者: pitpatagain | 发布于: 2025-08-05 17:39</sub>

---
