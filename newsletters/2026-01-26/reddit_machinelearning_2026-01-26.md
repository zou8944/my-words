## Reddit ML - 2026-01-26


### 1. [ICML 2026：我的论文被拒，却让我继续当审稿人？](https://www.reddit.com/r/MachineLearning/comments/1qmhyin/d_icml_2026_icml_deskrejected_my_paper_but_kept/)
> 作者论文被ICML拒稿，却被要求继续担任审稿人，讽刺学术界的无偿劳动现象。

<sub>作者: /u/ParticularWork8424 | 发布于: 2026-01-25 12:34</sub>

---

### 2. [ICML新规：审稿人将接受元审稿人评估。此举是否明智？](https://www.reddit.com/r/MachineLearning/comments/1qmi3oe/d_icml_new_policy_reviewers_will_be_reviewed_by/)
> ICML 新政策：审稿人将由元审稿人评审，旨在提升审稿质量。

<sub>作者: /u/Striking-Warning9533 | 发布于: 2026-01-25 12:41</sub>

---

### 3. [[D] AI4PDEs、SciML与基础模型：未来将走向何方？](https://www.reddit.com/r/MachineLearning/comments/1qmg4t3/d_ai4pdes_sciml_foundational_models_where_are_we/)
> 作者作为计算力学学生，观察到AI4PDEs和科学机器学习领域研究分散，包括强化学习、神经算子、基础模型等多种方向，询问是否存在明确趋势以及机器人学习是否会融入科学ML。

<sub>作者: /u/Mundane_Chemist3457 | 发布于: 2026-01-25 10:54</sub>

---

### 4. [[P] 理解多头潜在注意力机制（MLA）](https://www.reddit.com/r/MachineLearning/comments/1qmjzjd/p_understanding_multihead_latent_attention_mla/)
> 对DeepSeek的多头潜在注意力机制进行解析，涵盖其原理、从MHA到MLA的演进路径，并提供PyTorch代码及KV缓存优化方法。

<sub>作者: /u/shreyansh26 | 发布于: 2026-01-25 14:06</sub>

---

### 5. [[讨论] 为何部分研究论文不将准确率作为评估指标？](https://www.reddit.com/r/MachineLearning/comments/1qmnnaa/r_why_do_some_research_papers_not_mention/)
> 作者疑惑为何眼科AI论文只报告AUC和PRC，而不包含准确率这一指标。

<sub>作者: /u/Illustrious_Park7068 | 发布于: 2026-01-25 16:26</sub>

---

### 6. [[D] DeepDanbooru v3 PyTorch移植版：加载权重后持续输出0.5或0](https://www.reddit.com/r/MachineLearning/comments/1qmftku/d_deepdanbooru_v3_pytorch_port_constant_05_or_0/)
> 用户将DeepDanbooru模型移植到PyTorch时，批归一化层导致所有标签输出恒为0.5，询问转换权重时的已知问题及解决方法。

<sub>作者: /u/RevolutionaryAge70 | 发布于: 2026-01-25 10:36</sub>

---

### 7. [SIGIR发表论文中的错误](https://www.reddit.com/r/MachineLearning/comments/1qml8ht/d_error_in_sigir_published_paper/)
> 用户指出SIGIR会议论文中关于BGE-M3模型参数数量（100M vs 实际600M）存在明显错误，并质疑审稿过程。

<sub>作者: /u/LouisAckerman | 发布于: 2026-01-25 14:57</sub>

---
