## AINews - 2025-07-23

> [原文链接](https://news.smol.ai/issues/25-07-22-not-much/)

## 📰 十大AI新闻要点

### 1. [Kimi K2 技术报告发布，声称在代理任务上达到SOTA](https://twitter.com/Kimi_Moonshot/status/1947520758760313170)
> Moonshot AI发布了1万亿参数的Kimi K2技术报告，详细介绍了MuonClip优化器、使用2万多种工具的大规模代理数据合成管道，以及联合RL对齐方法。该模型被描述为类似DeepSeekV3风格的MoE架构，但具有更高的稀疏性，并且是开源的。

---

### 2. [Qwen3-235B-A22B挑战Kimi K2，夺回基准榜首](https://twitter.com/huybery/status/1947345040470380614)
> 阿里巴巴更新了Qwen3模型，其Qwen3-235B-A22B变体在GPQA、AIME和LiveCodeBench等基准上击败了Kimi-K2、Claude-4 Opus和DeepSeek V3。该模型比Kimi 2小4.25倍（235B vs 1T参数），但使用GQA而非MLA。

---

### 3. [Google推出Gemini 2.5 Flash-Lite](https://twitter.com/Google/status/1947689382892204542)
> Google宣布稳定发布Gemini 2.5 Flash-Lite，这是其2.5系列中最具成本效益和最快的模型。Google DeepMind表示它在编码、数学和多模态理解方面优于2.0 Flash模型。

---

### 4. [Google DeepMind的Gemini正式获得IMO金牌](https://twitter.com/AndrewLampinen/status/1947370582393425931)
> Demis Hassabis宣布，Gemini Deep Think的高级版本在国际数学奥林匹克竞赛（IMO）中获得了金牌级别的分数（35/42），这是AI模型的首次。

---

### 5. [OpenAI宣布与Oracle合作建设5GW数据中心](https://twitter.com/OpenAI/status/1947628731142648113)
> OpenAI正在与Oracle合作开发额外的4.5吉瓦“Stargate”数据中心容量，使总容量超过5 GW。位于德克萨斯州阿比林的Stargate I站点已开始上线。

---

### 6. [Perplexity Comet浏览器获得关注](https://twitter.com/AravSrinivas/status/1947407684996894969)
> Perplexity AI的新浏览器Comet的等待名单自推出以来翻了一番。早期用户反馈表明它使传统的聊天界面“感觉过时”。

---

### 7. [LangChain 1.0即将发布](https://twitter.com/hwchase17/status/1947376920355917909)
> Harrison Chase宣布团队正在开发LangChain 1.0，将专注于成为构建LLM应用程序的最简单起点，并提供基于LangGraph的通用代理架构。

---

### 8. [OpenAI在肯尼亚推出临床Copilot](https://twitter.com/gdb/status/1947732134430687351)
> OpenAI与肯尼亚的PendaHealth合作，研究了4万次患者访问中使用OpenAI驱动的临床Copilot的成果。

---

### 9. [LlamaIndex发布开源RFP响应代理](https://twitter.com/jerryjliu0/status/1947465066892431792)
> LlamaIndex构建了一个完全开源的代理，用于自动化RFP响应。该应用程序基于LlamaIndex框架和LlamaCloud，处理文档提取、分析和报告生成。

---

### 10. [xAI的Colossus超级集群扩展](https://x.com/elonmusk/status/1947701807389515912)
> Elon Musk透露，xAI的Grok正在使用名为Colossus 1的超算集群进行训练，该集群拥有23万张GPU（包括3万张最新一代GB200），并计划为Colossus 2部署额外的55万张GB200和GB300 GPU。

---

## 🛠️ 十大工具产品要点

### 1. [Qwen3-Coder-480B-A35B发布](https://qwenlm.github.io/blog/qwen3-coder/)
> 阿里巴巴发布了Qwen3-Coder，这是一个480B总参数的MoE模型，专为编码和代理任务设计，具有100万token的上下文窗口，并在SWE-bench上表现出色。

---

### 2. [MegaTTS 3语音克隆工具](https://huggingface.co/spaces/mrfakename/MegaTTS3-Voice-Cloning)
> MegaTTS 3的WavVAE编码器已发布，支持多样化的口音和音色克隆，模型和演示现已在Hugging Face上提供。

---

### 3. [vLLM与Hugging Face Transformers集成](https://twitter.com/vllm_project/status/1947756551663718754)
> vLLM项目宣布支持开箱即用的视觉语言模型与Transformers的集成，简化了多模态模型的部署和推理。

---

### 4. [Perplexity Comet浏览器](https://twitter.com/AravSrinivas/status/1947407684996894969)
> Perplexity AI的新浏览器Comet因其代理能力而受到广泛关注，用户反馈表明它使传统聊天界面“感觉过时”。

---

### 5. [LangChain 1.0](https://twitter.com/hwchase17/status/1947376920355917909)
> LangChain 1.0将专注于成为构建LLM应用程序的最简单起点，并提供基于LangGraph的通用代理架构。

---

### 6. [Anthropic增强移动端Artifacts功能](https://twitter.com/AnthropicAI/status/1947690894888513964)
> Anthropic推出了新的移动端Artifacts交互方式，允许用户创建交互式工具、浏览画廊并直接从手机分享作品。

---

### 7. [LlamaIndex的RFP响应代理](https://twitter.com/jerryjliu0/status/1947465066892431792)
> LlamaIndex构建了一个完全开源的代理，用于自动化RFP响应，处理文档提取、分析和报告生成。

---

### 8. [AMD Strix Halo "Ryzen AI MAX" APU](https://wccftech.com/amd-strix-halo-ryzen-ai-max-apus-diy-pc-new-modt-mini-itx-motherboards-128-gb-lpddr5x-memory/)
> AMD的Strix Halo "Ryzen AI MAX" APU通过新的MoDT Mini-ITX主板提供给DIY PC构建者，支持高达128GB的LPDDR5X内存。

---

### 9. [ik_llama.cpp仓库恢复](https://github.com/ikawrakow/ik_llama.cpp)
> ik_llama.cpp仓库已在GitHub上恢复，提供了Llama模型的C++推理代码，强调了定期备份关键仓库的重要性。

---

### 10. [Hugging Face Hub的FP8训练](https://github.com/pytorch/torchtune/pull/2546)
> 开发者在Axolotl中尝试将FP8训练与DDP和torch.compile结合时遇到了关键错误，目前正在寻求解决方案。

---