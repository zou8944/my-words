## AINews - 2025-10-05

> [原文链接](https://news.smol.ai/issues/25-10-03-not-much/)

## 📰 十大AI新闻要点

### 1. [Anthropic任命新CTO](https://x.com/zeffmax/status/1973833211835974046?s=46)
> Anthropic公司宣布任命新的首席技术官，这是该公司在DevDay前的重要人事变动

---

### 2. [Claude Sonnet 4.5编码能力评测](https://twitter.com/finbarrtimbers/status/1973922679418974298)
> 经过约30小时测试，Claude Sonnet 4.5在编码方面表现与Opus 4.1相当，用户体验流畅但不如GPT-5 Codex强大，同时Anthropic强调其在网络安全防御能力上的优势

---

### 3. [xAI Grok Code Fast编码性能声称](https://twitter.com/gauravisnotme/status/1974001009778115066)
> Grok Code Fast据称在较低成本下实现比Claude 4.5和GPT-5 Codex更高的编辑成功率，需要独立验证，用户更关注编辑可靠性而非原始指标

---

### 4. [Google Jules编程助手发布公共API](https://twitter.com/julesagent/status/1974178592683954252)
> Google的Jules编码助手结束为期一周的发布活动，推出公共API使其成为"可编程团队成员"，支持工具集成和CI/CD流程

---

### 5. [Sora 2 Pro视频生成能力突破](https://twitter.com/billpeeb/status/1974035563482116571)
> Sora 2登上App Store榜首，团队快速迭代并发放邀请，高质量15秒视频片段正在推出，同时驱动新的创作者生态系统

---

### 6. [Sakana AI与Daiwa证券达成3400万美元合作](https://twitter.com/SakanaAILabs/status/1973935631354245286)
> Sakana AI与Daiwa证券签署多年期合作协议，共同构建"全面资产咨询平台"，利用AI模型进行研报生成、市场分析和投资组合构建

---

### 7. [Terence Tao使用GPT-5进行数学研究](https://twitter.com/SebastienBubeck/status/1973977315572154383)
> 菲尔兹奖得主陶哲轩公开记录使用GPT-5和工具搜索数学反例和启发式方法，这被认为是人类+AI研究工作流的标志性时刻

---

### 8. [xLSTM架构报告性能优势](https://twitter.com/maxmbeck/status/1974018534385598895)
> xLSTM在固定FLOP和固定损失条件下报告Pareto主导Transformer，在下游推理效率方面获得增益

---

### 9. [Perplexity Comet浏览器全球发布](https://www.perplexity.ai/comet)
> Perplexity的AI优先Comet浏览器结束等待名单，向全球用户免费开放，支持并行代理任务，获得用户热情采用

---

### 10. [Huawei SINQ量化方法突破](https://arxiv.org/pdf/2509.22944)
> 华为提出SINQ后训练量化方案，无需校准数据，比AWQ快30倍，在4位及以下量化中改善困惑度，代码已在GitHub发布

---

## 🛠️ 十大工具产品要点

### 1. [Google Jules工具终端接口](https://twitter.com/julesagent/status/1974178592683954252)
> 可通过npm install -g @google/jules安装，提供终端界面支持异步编码代理，与Gemini CLI集成

---

### 2. [Chrome DevTools MCP发布](https://github.com/ChromeDevTools/chrome-devtools-mcp)
> 标准化的Chrome开发者工具MCP，为代理提供浏览器调试和自动化表面的标准化访问

---

### 3. [TorchAO INT4量化集成](https://github.com/pytorch/ao?tab=readme-ov-file#-quick-start)
> TorchAO集成tinygemm的INT4量化，使用TensorCore内核，针对A100部署的高吞吐量优化

---

### 4. [DeepSeek稀疏注意力CUDA实现](https://github.com/deepseek-ai/FlashMLA)
> 使用FlashMLA和TileLang实现DeepSeek稀疏注意力，支持部分RoPE和FP8稀疏内核

---

### 5. [KernelBench GPU性能评估系统](https://harvard-edge.github.io/cs249r_fall2025/blog/2024/10/01/gpu-performance-engineering/)
> 包含250个精选PyTorch ML工作负载，引入fast_p加速指标，系统化GPU性能评估

---

### 6. [Solveit AI增强开发平台发布](https://xcancel.com/jeremyphoward/status/1973857739341508884)
> Jeremy Howard宣布Solveit公开版本，提供5周直播课程，用于系统管理、应用部署、GUI开发和合同起草

---

### 7. [vLLM在Qwen3-0.6B上实现4300 t/s](来源：文章内容)
> 在RTX 4070上，Qwen3-0.6B BF16使用vLLM达到4300 token/秒，远超transformers的10-11 t/s

---

### 8. [Ollama本地工具调用支持](https://ollama.com/)
> 提供简单方式使用工具调用（函数调用），设置与OpenAI API兼容的本地服务器

---

### 9. [Red Hat发布FP8量化Qwen3-VL-235B](https://twitter.com/RedHat_AI/status/1973932224400798163)
> FP8量化版本减少约50%磁盘/GPU内存使用，保持>99.6%准确率

---

### 10. [Ant Group Ling 2.0 FP8训练栈开源](https://twitter.com/ZhihuFrontier/status/1974182694239285260)
> 开源FP8原生混合精度MoE训练栈，报告BF16级别准确率，30-60%吞吐量增益

---