## Reddit ML - 2026-01-12


### 1. [[D] 双盲评审不过是场幻觉…](https://www.reddit.com/r/MachineLearning/comments/1q9spsk/d_double_blind_review_is_such_an_illusion/)
> 用户批评顶尖实验室在论文未经同行评审时，就通过预印本和社交媒体过度宣传，形成“媒体审判”，认为学术体系需改革。

<sub>作者: /u/casualcreak | 发布于: 2026-01-11 07:01</sub>

---

### 2. [[R] 为何双重随机矩阵（使用Sinkhorn-Knopp算法）仅在DeepSeek的mHC论文中流行，而未在早期RNN论文中普及？](https://www.reddit.com/r/MachineLearning/comments/1qa0n65/r_why_doubly_stochastic_matrix_idea_using/)
> 探讨为何在循环神经网络时代未广泛讨论使用双随机矩阵来稳定梯度，该想法因能防止梯度消失或爆炸而受关注。

<sub>作者: /u/Delicious_Screen_789 | 发布于: 2026-01-11 14:26</sub>

---

### 3. [[D] 本科生如何获得研究/机器学习实习机会](https://www.reddit.com/r/MachineLearning/comments/1q9r7br/d_how_to_get_research_ml_internships_as_a/)
> 本科生寻求有薪的机器学习研究实习或兼职，目前有无薪研究经历并有论文在投。

<sub>作者: /u/Correct_Scene143 | 发布于: 2026-01-11 05:38</sub>

---

### 4. [[P] PerpetualBooster：新型梯度提升库，实现O(n)持续学习，在表格数据基准测试中超越AutoGluon。](https://www.reddit.com/r/MachineLearning/comments/1qa351n/p_perpetualbooster_a_new_gradient_boosting/)
> 团队推出PerpetualBooster梯度提升算法，解决传统GBDT框架的遗忘和重训练瓶颈，支持O(n)复杂度的持续学习，并配套无服务器云平台。

<sub>作者: /u/mutlu_simsek | 发布于: 2026-01-11 16:08</sub>

---

### 5. [[D] 大家在长上下文推理时遇到过KV缓存/内存带宽瓶颈吗？](https://www.reddit.com/r/MachineLearning/comments/1q9syiz/d_anyone_running_into_kv_cache_memory_bandwidth/)
> 用户探讨长上下文下Transformer模型推理的KV缓存内存带宽瓶颈，并询问生产中的实际解决方案与取舍。

<sub>作者: /u/biletnikoff_ | 发布于: 2026-01-11 07:15</sub>

---

### 6. [[讨论] 长时间训练中，如何做到代码前几次尝试就能正常运行？](https://www.reddit.com/r/MachineLearning/comments/1qa46hz/d_during_long_training_sessions_how_do_you_manage/)
> 用户询问在长时间模型训练中，如何监控部分数据或特定情况下的模型失败，并有效保存检查点以避免计算资源浪费。

<sub>作者: /u/Specialist-Pool-6962 | 发布于: 2026-01-11 16:47</sub>

---

### 7. [[R] 更新了我的机器学习笔记：加入DeepSeek全新mHC模型](https://www.reddit.com/r/MachineLearning/comments/1qa0taf/r_updated_my_machine_learning_note_with_deepseeks/)

<sub>作者: /u/Delicious_Screen_789 | 发布于: 2026-01-11 14:34</sub>

---

### 8. [地平线作为特征的预测 [D]](https://www.reddit.com/r/MachineLearning/comments/1q9lsdf/horizonasafeature_forecasting_d/)
> 用户询问在长预测期多期预测中使用“将预测期作为特征”方法的经验，并分享了自己用此方法取得较好指标的结果。

<sub>作者: /u/BearPros2920 | 发布于: 2026-01-11 01:19</sub>

---

### 9. [[讨论] 设计一个直接生成Markdown而非原始HTML的爬虫](https://www.reddit.com/r/MachineLearning/comments/1qa20k5/d_designing_a_crawler_that_produces_ready/)
> 作者设计了一个专为AI数据摄取优化的网络爬虫，能提取核心内容、转换为结构化Markdown，并支持增量更新，旨在简化RAG流程。

<sub>作者: /u/rgztmalv | 发布于: 2026-01-11 15:23</sub>

---

### 10. [[D] 时间序列分类中词袋方法的原理是什么？](https://www.reddit.com/r/MachineLearning/comments/1q9y5b8/d_what_is_the_intuition_behind_bag_of_word/)
> 用户质疑将时间序列转换为字符串的动机，询问这是否仅为适配分类模型，还是有其理论依据。

<sub>作者: /u/al3arabcoreleone | 发布于: 2026-01-11 12:27</sub>

---
