- **[MobileLLM-R1：Meta发布的高效小型推理模型](https://huggingface.co/facebook/MobileLLM-R1-950M)**（来源：Hugging Face）  
  > 参数小于10亿，在MATH准确率上超越同类模型，适用于边缘设备推理，提升移动端AI性能。

- **[Qwen3-Next-80B：阿里巴巴稀疏激活MoE模型](https://huggingface.co/collections/Qwen/qwen3-next-68c25fd6838e585db8eeea9d)**（来源：Hugging Face）  
  > 混合注意力设计，稀疏度3.8%，支持256k上下文，推理速度提升10倍，需SGLang和vLLM适配。

- **[OpenPI：机器人视觉语言动作模型](https://github.com/Physical-Intelligence/openpi)**（来源：GitHub）  
  > 基于万小时机器人数据训练，支持零样本推理和微调，适用于ALOHA/DROID平台任务泛化。

- **[ROMA：递归分层多智能体框架](https://github.com/sentient-agi/ROMA)**（来源：GitHub）  
  > 通过原子化分解和并行执行解决复杂任务，支持LLM/API混合调用，适用于高性能多智能体系统。

- **[Codebuff：开源AI编程助手](https://github.com/CodebuffAI/codebuff)**（来源：GitHub）  
  > 多智能体协作实现自然语言指令修改代码，在真实编程任务中准确率达61%，超越Claude Code。

- **[Hugging Face Transformers v5现代化升级](https://twitter.com/art_zucker/status/1966470835558093226)**（来源：Twitter）  
  > 推出更快内核和连续批处理，简化评估/训练循环，专注于修补和工具箱而非最大吞吐量服务器。

- **[开源维护者如何优雅地说“不”](https://news.ycombinator.com/item?id=45234593)**（来源：Hacker News）  
  > 提供开源项目维护者拒绝不合理请求的实用指南，帮助维护者平衡社区贡献与项目可持续性。

- **[使用量化方法测试投资配置的平台](https://news.ycombinator.com/item?id=45235042)**（来源：Hacker News）  
  > 让用户自主测试股票、ETF和加密货币的优化配置方案，将量化工具以友好方式开放给普通用户。

- **[VeritasGraph：本地部署图检索增强生成系统](https://news.ycombinator.com/item?id=45235033)**（来源：Hacker News）  
  > 用知识图谱替代向量搜索，解决多跳查询问题，提供可验证溯源和本地部署，确保AI可信度。

- **[为什么下载不能立刻到达最快速度](https://sspai.com/prime/story/download-speed-and-congestion-control-algo)**（来源：少数派）  
  > 从现象分析拥塞控制算法，解释下载速度逐步提升的原因，帮助优化网络传输策略。