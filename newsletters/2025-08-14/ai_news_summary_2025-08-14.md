## AINews - 2025-08-14

> [原文链接](https://news.smol.ai/issues/25-08-11-ioi-gold/)

## 📰 十大AI新闻要点

### 1. [OpenAI模型在IOI竞赛中达到金牌水平](https://x.com/OpenAI/status/1954969035713687975)
> OpenAI宣布其推理系统在国际信息学奥林匹克竞赛(IOI)在线比赛中获得金牌级别的表现，排名超过295名人类选手，位列全球前2%。这是继上月IMO金牌后，OpenAI模型在另一项顶级学术竞赛中的突破性表现。

---

### 2. [GPT-5发布引发用户反弹](https://twitter.com/scaling01/status/1954609552810459203)
> GPT-5发布后因初始使用限制和移除用户模型选择权引发"ChatGPT Plus反抗"。社区压力迫使OpenAI将"Thinking"模型的请求限制提高到每周3000次，并重新添加模型选择器。

---

### 3. [OpenAI计划5个月内算力翻倍](https://i.redd.it/bgny6nt8thif1.jpeg)
> OpenAI宣布将在未来5个月内将计算资源翻倍，推测是为Sora 2、高级语音功能和GPT-5等即将发布的模型做准备。社区讨论集中在免费层优先策略可能是为获取数据和市场份额。

---

### 4. [Claude新增跨对话引用功能](https://twitter.com/AnthropicAI/status/1954999404387242362)
> Anthropic为Claude推出跨对话引用功能，允许模型搜索并整合之前的聊天记录到新会话中。该功能目前向Max、Team和Enterprise用户推出，显著改善了多轮工作流的上下文连续性。

---

### 5. [Meta AI赢得2025年Algonauts脑建模竞赛](https://twitter.com/AIatMeta/status/1954865388749205984)
> Meta AI的Brain & AI团队凭借1B参数的TRIBE(Trimodal Brain Encoder)模型在Algonauts 2025脑建模竞赛中获得第一名，这是首个能预测视觉、听觉和文本刺激下大脑反应的深度神经网络。

---

### 6. [清华教授发现40年来最快最短路径算法](https://twitter.com/algo_diver/status/1954423622787039379)
> 清华大学教授发现了40年来最快的图最短路径算法，打破了Dijkstra 1984年建立的"排序障碍"。这一结果在学术界引起广泛关注，相关推文获得超过5500次转发。

---

### 7. [扩散语言模型(DLMs)数据效率优于自回归模型](https://twitter.com/arankomatsuzaki/status/1954242373145543134)
> 一系列论文比较显示，扩散语言模型比自回归模型更具数据效率优势。在数据日益受限的背景下，这一发现可能影响未来语言模型的发展方向。

---

### 8. [OpenAI开源模型gpt-oss-120b表现优异](https://i.redd.it/0lv50zsy1dif1.png)
> OpenAI的开源模型gpt-oss-120b在lmarena.ai排行榜上排名第16位，超过多个强劲竞争对手。该模型在保持较低计算需求的同时实现了有竞争力的基准测试结果。

---

### 9. [斯坦福和CMU研究显示AI陪伴与孤独感相关](https://twitter.com/DeepLearningAI/status/1954226191071576552)
> 斯坦福和卡内基梅隆大学的研究分析了1000多名Character.AI用户，发现对AI机器人陪伴的依赖程度越高，用户满意度和孤独感越低。这引发了关于AI人际关系影响的讨论。

---

### 10. [中国发布GLM-4.5和Qwen新模型](https://twitter.com/teortaxesTex/status/1954754947892850913)
> 智谱AI发布GLM-4.5技术报告，详细介绍其使用slime框架的复杂后训练策略。阿里巴巴的Qwen团队则展示了Qwen3-Coder生成SVG图像的能力和百万token上下文处理能力。

---

## 🛠️ 十大工具产品要点

### 1. [Cursor推出CLI测试版](https://cursor.com/blog/cli)
> Cursor发布早期测试版终端体验，支持所有模型并在CLI和编辑器之间无缝切换。社区认为这是Claude Code的有力竞争者，正在测试其定价和API密钥流程。

---

### 2. [LlamaIndex支持GPT-5并推出Agent Maze挑战](https://t.co/JCZCSVUAed)
> LlamaIndex发布对GPT-5的当日支持，并通过Agent Maze挑战展示轻量级代理评估功能。用户需要升级到v0.13.x包以获取完整功能。

---

### 3. [Claude Context代码搜索插件开源](https://github.com/zilliztech/claude-context)
> 该插件支持大规模代码库(数百万行)的语义搜索，利用向量数据库进行上下文检索，通过AST分析的智能代码分块保留代码语义，解决了上下文窗口/令牌成本限制。

---

### 4. [Axolotl引入N-D并行训练](https://huggingface.co/blog/accelerate-nd-parallel)
> Axolotl通过Accelerate实现跨多个维度的并行训练，提高了大型模型/数据集的吞吐量。工程师认为这是无需手工分片逻辑即可进行复杂模型训练的实用路径。

---

### 5. [Unsloth发布免费GPT-OSS微调Colab](https://x.com/UnslothAI/status/1953896997867729075)
> Unsloth提供免费Colab来微调gpt-oss，声称20B模型可在14GB VRAM上训练，120B模型只需65GB，使预算有限的用户也能进行大规模SFT目标微调。

---

### 6. [Qwen3-Coder和Qwen3-2507发布](https://docs.unsloth.ai/basics/qwen3-coder)
> Qwen3-Coder和Qwen3-2507模型发布，附带指南和通过Unsloth的上传。早期讨论认为它们是具有实用微调配方的SOTA级编码变体，适合快速采用。

---

### 7. [Excel Ollama插件发布](https://www.listendata.com/2025/08/ollama-in-excel.html)
> 新开发的Excel插件直接集成Ollama(LLM后端)，允许用户通过自定义公式`=ollama(A1)`调用LLM补全，强调数据永不离开Excel，并支持通过拖拽填充进行批量应用。

---

### 8. [LangChain发布代理可靠性指南](https://twitter.com/LangChainAI/status/1954233716487958845)
> LangChain团队发布处理幻觉和验证工具使用的实用指南，同时宣布与Oxylabs的高级网页抓取集成，以及新的LangGraph CLI用于从终端管理助手。

---

### 9. [whisper.cpp集成到ffmpeg](https://twitter.com/ggerganov/status/1954988938281533532)
> whisper.cpp正被集成到ffmpeg中，这是本地音频处理的重大进展。社区认为这将大大简化音频转录和处理的开发流程。

---

### 10. [Google发布LangExtract库](https://twitter.com/algo_diver/status/1954424008767951106)
> Google推出LangExtract，这是一个Python库，可从非结构化文档中提取结构化数据并提供精确的来源归属，有望改善文档处理和信息提取工作流。